{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59dd1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import joblib\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import models\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3136e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/flipkart-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d28878d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>crawl_timestamp</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category_tree</th>\n",
       "      <th>pid</th>\n",
       "      <th>retail_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>image</th>\n",
       "      <th>is_FK_Advantage_product</th>\n",
       "      <th>description</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_specifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15989</th>\n",
       "      <td>09e38163979db5514e8c5b84fcdb6ecf</td>\n",
       "      <td>2015-12-29 05:07:38 +0000</td>\n",
       "      <td>http://www.flipkart.com/destudio-large-wall-st...</td>\n",
       "      <td>DeStudio Large WALL STICKER Sticker</td>\n",
       "      <td>[\"Home Decor &amp; Festive Needs &gt;&gt; Wall Decor &amp; C...</td>\n",
       "      <td>STIEYZ5XTSCXZHWS</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>699.0</td>\n",
       "      <td>[\"http://img6a.flixcart.com/image/sticker/a/g/...</td>\n",
       "      <td>False</td>\n",
       "      <td>Buy DeStudio Large WALL STICKER Sticker for Rs...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>DeStudio</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Sales Pack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13720</th>\n",
       "      <td>c340914b07f03c05731f9541d77b1dcb</td>\n",
       "      <td>2016-03-03 14:52:00 +0000</td>\n",
       "      <td>http://www.flipkart.com/nino-bambino-full-slee...</td>\n",
       "      <td>Nino Bambino Full Sleeve Polka Print Baby Girl...</td>\n",
       "      <td>[\"Clothing &gt;&gt; Kids' Clothing &gt;&gt; Infants Wear &gt;...</td>\n",
       "      <td>SWSEG87FPRCXGZDP</td>\n",
       "      <td>849.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>[\"http://img5a.flixcart.com/image/sweatshirt/h...</td>\n",
       "      <td>False</td>\n",
       "      <td>Key Features of Nino Bambino Full Sleeve Polka...</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>No rating available</td>\n",
       "      <td>Nino Bambino</td>\n",
       "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Knit Type\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uniq_id            crawl_timestamp  \\\n",
       "15989  09e38163979db5514e8c5b84fcdb6ecf  2015-12-29 05:07:38 +0000   \n",
       "13720  c340914b07f03c05731f9541d77b1dcb  2016-03-03 14:52:00 +0000   \n",
       "\n",
       "                                             product_url  \\\n",
       "15989  http://www.flipkart.com/destudio-large-wall-st...   \n",
       "13720  http://www.flipkart.com/nino-bambino-full-slee...   \n",
       "\n",
       "                                            product_name  \\\n",
       "15989                DeStudio Large WALL STICKER Sticker   \n",
       "13720  Nino Bambino Full Sleeve Polka Print Baby Girl...   \n",
       "\n",
       "                                   product_category_tree               pid  \\\n",
       "15989  [\"Home Decor & Festive Needs >> Wall Decor & C...  STIEYZ5XTSCXZHWS   \n",
       "13720  [\"Clothing >> Kids' Clothing >> Infants Wear >...  SWSEG87FPRCXGZDP   \n",
       "\n",
       "       retail_price  discounted_price  \\\n",
       "15989        1998.0             699.0   \n",
       "13720         849.0             849.0   \n",
       "\n",
       "                                                   image  \\\n",
       "15989  [\"http://img6a.flixcart.com/image/sticker/a/g/...   \n",
       "13720  [\"http://img5a.flixcart.com/image/sweatshirt/h...   \n",
       "\n",
       "      is_FK_Advantage_product  \\\n",
       "15989                   False   \n",
       "13720                   False   \n",
       "\n",
       "                                             description       product_rating  \\\n",
       "15989  Buy DeStudio Large WALL STICKER Sticker for Rs...  No rating available   \n",
       "13720  Key Features of Nino Bambino Full Sleeve Polka...  No rating available   \n",
       "\n",
       "            overall_rating         brand  \\\n",
       "15989  No rating available      DeStudio   \n",
       "13720  No rating available  Nino Bambino   \n",
       "\n",
       "                                  product_specifications  \n",
       "15989  {\"product_specification\"=>[{\"key\"=>\"Sales Pack...  \n",
       "13720  {\"product_specification\"=>[{\"key\"=>\"Knit Type\"...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4a7bc",
   "metadata": {},
   "source": [
    "* # Working Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1dd1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_data(data):\n",
    "\n",
    "    def normalize_text(text):\n",
    "        text = text.lower()  # Convert text to lowercase\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub('[^A-Za-z0-9]+', ' ', text)  # Remove non-alphanumeric characters (special chars)\n",
    "        text = re.sub('\\n', ' ', text)  # Remove newlines\n",
    "        text = re.sub(' +', ' ', text)  # Remove extra spaces\n",
    "        text = text.strip()  # Remove leading/trailing spaces\n",
    "        return text\n",
    "       \n",
    "    def repair(text):\n",
    "        text = str(text)\n",
    "        pattern = re.compile('[\\([{})\\]]')\n",
    "        text= pattern.sub(r'',text)\n",
    "        text = text.replace('\"','')\n",
    "        text = text.replace(',','')\n",
    "        text = text.replace('&','')\n",
    "        pattern = re.compile('>>')\n",
    "        return pattern.sub(r'',text)\n",
    "    \n",
    "    def remove_stopwords(text):\n",
    "        stop_words = set(stopwords.words('english'))  # Use set for faster lookups\n",
    "        words = text.split()\n",
    "        filtered_sentence = ' '.join([word for word in words if word not in stop_words])\n",
    "        return filtered_sentence\n",
    "    \n",
    "    def remove_punctuation(text):\n",
    "        table = str.maketrans('', '', string.punctuation)  # Create translation table\n",
    "        words = text.split()\n",
    "        filtered_sentence = ' '.join([word.translate(table) for word in words])  # Efficient punctuation removal\n",
    "        return filtered_sentence\n",
    "    \n",
    "    def stemming(text):\n",
    "        text = str(text)\n",
    "        stemmer = PorterStemmer()\n",
    "        return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    \n",
    "    def lemmatizing(text):\n",
    "        text = str(text)\n",
    "        lemmet = WordNetLemmatizer()\n",
    "        return \" \".join([lemmet.lemmatize(word) for word in text.split()])\n",
    "\n",
    "    print(\"step 1 : Cleaning product_category_tree.....\")\n",
    "    data['product_category_tree'] = data['product_category_tree'].apply(repair)\n",
    "    \n",
    "    print(\"step 2 : Cleaning description.....\")\n",
    "    data['description'] = data['description'].apply(repair)\n",
    "\n",
    "    print(\"step 3 : Creating 'desc' column.....\")\n",
    "    data['desc'] = data['product_category_tree']+data['description']\n",
    "    \n",
    "    print(\"step 4 : Normalizing 'desc' column.....\")\n",
    "    data['desc'] = data['desc'].apply(normalize_text)\n",
    "\n",
    "    print(\"step 5 : stopwords removal 'desc'.....\")\n",
    "    data['desc'] = data['desc'].apply(remove_stopwords)\n",
    "\n",
    "    print(\"step 6: Removing punctuation 'desc'.....\")\n",
    "    data['desc'] = data['desc'].apply(remove_punctuation)\n",
    "\n",
    "    print(\"step 7 : Stemming 'desc' column.....\")\n",
    "    data['desc'] = data['desc'].apply(stemming)\n",
    "    \n",
    "    print(\"step 8 : Lemmatizing 'desc' column.....\")\n",
    "    data['desc'] = data['desc'].apply(lemmatizing)\n",
    "    \n",
    "    print(\"step 9 : Dropping unnecessary columns.....\")\n",
    "    data = data.drop(['uniq_id', 'crawl_timestamp', 'product_url', 'retail_price',\n",
    "                       'discounted_price','image', 'is_FK_Advantage_product', 'product_rating',\n",
    "                       'overall_rating','brand','product_specifications','product_category_tree','description'],axis=1)\n",
    "    \n",
    "    print(\"step 10 : Dropping null values.....\")\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    print(\"step 11 : ReCreating 'pid' column.....\")\n",
    "    data['pid'] = range(1, 20001)\n",
    "    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba74b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 : Cleaning product_category_tree.....\n",
      "step 2 : Cleaning description.....\n",
      "step 3 : Creating 'desc' column.....\n",
      "step 4 : Normalizing 'desc' column.....\n",
      "step 5 : stopwords removal 'desc'.....\n",
      "step 6: Removing punctuation 'desc'.....\n",
      "step 7 : Stemming 'desc' column.....\n",
      "step 8 : Lemmatizing 'desc' column.....\n",
      "step 9 : Dropping unnecessary columns.....\n",
      "step 10 : Dropping null values.....\n",
      "step 11 : ReCreating 'pid' column.....\n"
     ]
    }
   ],
   "source": [
    "working_data = working_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbe1c3",
   "metadata": {},
   "source": [
    "* ### Bag of Words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52b6ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(data):\n",
    "    print(\"Creating bag of words matrix.....\")\n",
    "    bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "    bow_matrix = bow_vectorizer.fit_transform(data['desc']).toarray()\n",
    "    return bow_matrix, bow_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960a6e4",
   "metadata": {},
   "source": [
    "* ### TF-IDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2540650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(data):\n",
    "    print(\"Creating tf-idf matrix.....\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(data['desc']).toarray()\n",
    "    return tfidf_matrix, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49c941",
   "metadata": {},
   "source": [
    "* ### Word2Vec function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d7c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vector(data):\n",
    "    print(\"Creating word2vec matrix.....\")\n",
    "    tokenized_sentences = data['desc'].apply(lambda x: x.split())\n",
    "    vector_size = 100  # Size of the word vectors\n",
    "    w2v_model = models.Word2Vec(sentences=tokenized_sentences, vector_size=vector_size, window=5, min_count=1, workers=4)\n",
    "    sentence_embeddings = []\n",
    "    for sentence in tokenized_sentences:\n",
    "        vectors = [w2v_model.wv[word] for word in sentence if word in w2v_model.wv]\n",
    "        if vectors:\n",
    "            sentence_embeddings.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            sentence_embeddings.append(np.zeros(vector_size))  # fallback for empty sentences\n",
    "    w2v_matrix = np.array(sentence_embeddings)\n",
    "    return w2v_matrix, w2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f623bab",
   "metadata": {},
   "source": [
    "* ### GloVe function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2622155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove(data, glove_file_path):\n",
    "    max_words = 20000\n",
    "    max_len = 3440\n",
    "    embedding_dim = 100\n",
    "\n",
    "    def tokenize_text(text, max_words=20000):\n",
    "        print('.....Tokenizing text...')\n",
    "        tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "        tokenizer.fit_on_texts(text)\n",
    "        sequences = tokenizer.texts_to_sequences(text)\n",
    "        return sequences, tokenizer\n",
    "\n",
    "    def pad_sequences_data(sequences, maxlen=200):\n",
    "        print('.....Padding sequences...')\n",
    "        padded_sequences = pad_sequences(sequences,maxlen=maxlen, padding='post', truncating='post')\n",
    "        return padded_sequences\n",
    "\n",
    "    def load_glove_embeddings(glove_file_path):\n",
    "        print('.....Loading GloVe embeddings...')\n",
    "        embeddings_index = {}\n",
    "        with open(glove_file_path, 'r', encoding='utf8') as f:\n",
    "            for line in f:\n",
    "                values = line.strip().split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = vector\n",
    "        return embeddings_index\n",
    "    \n",
    "    def glove_matrix(embedding_dim, tokenizer, embeddings_index):\n",
    "        print('......Creating embedding matrix...')\n",
    "        word_index = tokenizer.word_index\n",
    "        embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "        for word, i in word_index.items():\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "                \n",
    "        return embedding_matrix\n",
    "    \n",
    "    sequences, tokenizer = tokenize_text(data['desc'], max_words)\n",
    "    print(\"--\" * 20)\n",
    "    padded_sequences = pad_sequences_data(sequences, max_len)\n",
    "    print(\"--\" * 20)\n",
    "    embeddings_index = load_glove_embeddings(glove_file_path)\n",
    "    print(\"--\" * 20)\n",
    "    embedding_matrix = glove_matrix(embedding_dim, tokenizer, embeddings_index)\n",
    "    return padded_sequences, embedding_matrix, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b041dff",
   "metadata": {},
   "source": [
    "* ### FastText function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1cd6d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fasttext(data):\n",
    "    print(\"Creating FastText matrix.....\")\n",
    "    sentences = [row.split() for row in data['desc']]\n",
    "    phrases = Phrases(sentences = sentences, min_count = 30, progress_per = 10000)\n",
    "    sentences = phrases[sentences]\n",
    "    ft_model = FastText(vector_size=100, window = 5, min_count = 5, workers = 4, min_n = 1, max_n = 4)\n",
    "    ft_model.build_vocab(sentences)\n",
    "    ft_model.train(sentences, total_examples = ft_model.corpus_count, epochs = 20)\n",
    "    path = 'models/FastText.joblib'\n",
    "    joblib.dump(ft_model, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46ebada8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FastText matrix.....\n"
     ]
    }
   ],
   "source": [
    "train_fasttext(working_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31974d",
   "metadata": {},
   "source": [
    "* ### Similarity-Matrix function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d83a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(matrix):\n",
    "    print(\"Calculating similarity matrix.....\")\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5df5bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating word2vec matrix.....\n",
      "Creating bag of words matrix.....\n",
      "Creating tf-idf matrix.....\n",
      ".....Tokenizing text...\n",
      "----------------------------------------\n",
      ".....Padding sequences...\n",
      "----------------------------------------\n",
      ".....Loading GloVe embeddings...\n",
      "----------------------------------------\n",
      "......Creating embedding matrix...\n"
     ]
    }
   ],
   "source": [
    "w2v_matrix, w2v_model = word_to_vector(working_data)\n",
    "bow_matrix, bow_vectorizer = bag_of_words(working_data)\n",
    "tfidf_matrix, tfidf_vectorizer = tfidf(working_data)\n",
    "padded, glove_matrix, glove_tokenizer = glove(working_data, 'data/glove.6B.100d.txt')\n",
    "fasttext_matrix = joblib.load('models/FastText.joblib').wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ae821fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarity matrix.....\n",
      "Calculating similarity matrix.....\n",
      "Calculating similarity matrix.....\n",
      "Calculating similarity matrix.....\n",
      "Calculating similarity matrix.....\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix_bow = similarity_matrix(bow_matrix)\n",
    "similarity_matrix_tfidf = similarity_matrix(tfidf_matrix)\n",
    "similarity_matrix_w2v = similarity_matrix(w2v_matrix)\n",
    "similarity_matrix_glove = similarity_matrix(glove_matrix)\n",
    "similarity_matrix_fasttext = similarity_matrix(fasttext_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777b2fb",
   "metadata": {},
   "source": [
    "* ### Recommend function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18529800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(product,similarity_model):\n",
    "    product_index = data[data['product_name'] == product].index[0]\n",
    "    distances = similarity_model[product_index]\n",
    "    product_list = sorted(list(enumerate(distances)),reverse=True,key=lambda x: x[1])[1:6]\n",
    "    output={}\n",
    "    name_list = []\n",
    "    sim_list = []\n",
    "    for x in product_list:\n",
    "        prod_name = data.iloc[x[0]].product_name\n",
    "        name_list.append(prod_name)\n",
    "        prod_sim = np.round((x[1]*100),2)\n",
    "        sim_list.append(prod_sim)\n",
    "        \n",
    "    print('Checked Product :::::   ',product)    \n",
    "    name_list=np.array(name_list)\n",
    "    sim_list=np.array(sim_list)\n",
    "    dat = np.reshape([[name_list],[sim_list]],(2,5))\n",
    "    df = pd.DataFrame(dat.T,columns=['Recommended Product','Similarity(%age)'],index=[0,1,2,3,4])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e4d41",
   "metadata": {},
   "source": [
    "* ### Recommendations output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c5d4ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked Product :::::    FabHomeDecor Fabric Double Sofa Bed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommended Product</th>\n",
       "      <th>Similarity(%age)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MASARA Solid Women's Straight Kurta</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ploomz Women's Push-up Bra</td>\n",
       "      <td>50.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tatvaarts Tribal Danda Lady Showpiece  -  48.2...</td>\n",
       "      <td>49.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legrand Legrand Myrius 673010 16A Indicator Wh...</td>\n",
       "      <td>49.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sportking Women's Leggings</td>\n",
       "      <td>49.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Recommended Product Similarity(%age)\n",
       "0                MASARA Solid Women's Straight Kurta             63.5\n",
       "1                         Ploomz Women's Push-up Bra            50.27\n",
       "2  Tatvaarts Tribal Danda Lady Showpiece  -  48.2...            49.42\n",
       "3  Legrand Legrand Myrius 673010 16A Indicator Wh...            49.36\n",
       "4                         Sportking Women's Leggings            49.24"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = data.iloc[1].product_name\n",
    "# recommend_products(product,similarity_matrix_bow)\n",
    "# recommend_products(product,similarity_matrix_tfidf)\n",
    "# recommend_products(product,similarity_matrix_w2v)\n",
    "# recommend_products(product,similarity_matrix_glove)\n",
    "recommend_products(product,similarity_matrix_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d3aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
